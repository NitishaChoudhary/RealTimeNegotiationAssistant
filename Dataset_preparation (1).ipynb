{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea100d9-63d6-49f3-b9b9-0247f569524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analyze text\n",
    "result = sentiment_analyzer(\"I’m concerned about the display quality. I’ll look for a better option.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115bd64c-76d3-453d-9ffa-afabae34fe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in r:\\new folder\\anaconda.com\\lib\\site-packages (4.47.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in r:\\new folder\\anaconda.com\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in r:\\new folder\\anaconda.com\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in r:\\new folder\\anaconda.com\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in r:\\new folder\\anaconda.com\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in r:\\new folder\\anaconda.com\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in r:\\new folder\\anaconda.com\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in r:\\new folder\\anaconda.com\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in r:\\new folder\\anaconda.com\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.7 MB 4.2 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.8/9.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.6/9.7 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.4/9.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.5/9.7 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.0/9.7 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.8/9.7 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.6/9.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.6/9.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.7 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.1\n",
      "    Uninstalling transformers-4.47.1:\n",
      "      Successfully uninstalled transformers-4.47.1\n",
      "Successfully installed transformers-4.48.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8361389-5e2e-4fb9-ae6e-5e289e27f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarizer pipeline with BART model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Input text (customer's query)\n",
    "text = \"\"\"\n",
    "1. Hello, I am interested in touch screen laptops. Do you have any recommendations?\n",
    "2. What's the screen resolution on the Microsoft Surface laptop 5?\n",
    "3. Are there any trade-in offers if I exchange my old laptop?\n",
    "4. Does the stylus come with the laptop, or is it separate?\n",
    "5. This seems great, but I will check the style options first.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the input to encourage the model to output in the desired conversational structure\n",
    "formatted_text = \"\"\"\n",
    "Customer Inquiry Summary:\n",
    "1. Customer is asking for touch screen laptop recommendations.\n",
    "2. Customer wants to know the screen resolution of the Microsoft Surface Laptop 5.\n",
    "3. Customer is asking if there are any trade-in offers for exchanging an old laptop.\n",
    "4. Customer is asking if the stylus comes with the laptop or is purchased separately.\n",
    "5. Customer mentions they will check other style options before deciding.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the summary\n",
    "summary = summarizer(formatted_text, max_length=200, min_length=50, do_sample=False)\n",
    "\n",
    "# Print the summary\n",
    "print(\"Generated Summary:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87d29fa-3281-4073-b2e5-2977cc55a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting continuous buyer interaction...\n",
      "Listening for the buyer's input...\n",
      "Processing audio transcription...\n",
      "No clear speech detected in the last chunk.\n",
      "Waiting for the next buyer input...\n",
      "\n",
      "Listening for the buyer's input...\n",
      "Processing audio transcription...\n",
      "Transcription: I want some high resolution screen\n",
      "\n",
      "Buyer Transcription: I want some high resolution screen\n",
      "Waiting for the next interaction...\n",
      "\n",
      "Listening for the buyer's input...\n",
      "Processing audio transcription...\n",
      "No clear speech detected in the last chunk.\n",
      "Waiting for the next buyer input...\n",
      "\n",
      "Listening for the buyer's input...\n",
      "Processing audio transcription...\n",
      "Transcription: laptop\n",
      "\n",
      "Buyer Transcription: laptop\n",
      "Waiting for the next interaction...\n",
      "\n",
      "WARNING:tensorflow:From r:\\New folder\\anaconda.com\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From r:\\New folder\\anaconda.com\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n",
      "Device set to use 0\n",
      "Your max_length is set to 200, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "Customer Inquiry Summary: I want some high resolution screen. Customer is asking about laptop. Customer wants to know if there is a way to make the screen bigger. Customer would like to know how much it would cost to buy a new laptop. The customer would also want to know whether there was a way for the customer to make a new screen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the weights of TFBartForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n",
      "Device set to use 0\n",
      "Your max_length is set to 20, but your input_length is only 3. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=1)\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "ename": "SpreadsheetNotFound",
     "evalue": "<Response [404]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mr:\\New folder\\anaconda.com\\Lib\\site-packages\\gspread\\client.py:155\u001b[0m, in \u001b[0;36mClient.open_by_key\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     spreadsheet \u001b[38;5;241m=\u001b[39m Spreadsheet(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: key})\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32mr:\\New folder\\anaconda.com\\Lib\\site-packages\\gspread\\spreadsheet.py:29\u001b[0m, in \u001b[0;36mSpreadsheet.__init__\u001b[1;34m(self, http_client, properties)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_properties \u001b[38;5;241m=\u001b[39m properties\n\u001b[1;32m---> 29\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_sheet_metadata()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_properties\u001b[38;5;241m.\u001b[39mupdate(metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mr:\\New folder\\anaconda.com\\Lib\\site-packages\\gspread\\spreadsheet.py:230\u001b[0m, in \u001b[0;36mSpreadsheet.fetch_sheet_metadata\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Similar to :method spreadsheets_get:`gspread.http_client.spreadsheets_get`,\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03mget the spreadsheet form the API but by default **does not get the cells data**.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124;03mIt only retrieve the the metadata from the spreadsheet.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:rtype: dict\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mfetch_sheet_metadata(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid, params\u001b[38;5;241m=\u001b[39mparams)\n",
      "File \u001b[1;32mr:\\New folder\\anaconda.com\\Lib\\site-packages\\gspread\\http_client.py:305\u001b[0m, in \u001b[0;36mHTTPClient.fetch_sheet_metadata\u001b[1;34m(self, id, params)\u001b[0m\n\u001b[0;32m    303\u001b[0m url \u001b[38;5;241m=\u001b[39m SPREADSHEET_URL \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mid\u001b[39m\n\u001b[1;32m--> 305\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mr:\\New folder\\anaconda.com\\Lib\\site-packages\\gspread\\http_client.py:128\u001b[0m, in \u001b[0;36mHTTPClient.request\u001b[1;34m(self, method, endpoint, params, data, json, files, headers)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(response)\n",
      "\u001b[1;31mAPIError\u001b[0m: APIError: [-1]: <!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content=\"initial-scale=1, minimum-scale=1, width=device-width\">\n  <title>Error 404 (Not Found)!!1</title>\n  <style>\n    *{margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px}* > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>404.</b> <ins>That’s an error.</ins>\n  <p>The requested URL <code>/v4/spreadsheets/1Xv7HMn91ddcXhGXeLX-6jxYuVegfgnPIpFIPsZhcvPc/edit?gid=1072290330&amp;includeGridData=false</code> was not found on this server.  <ins>That’s all we know.</ins>\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mSpreadsheetNotFound\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 171\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChat session finalized and logged in Google Sheets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 160\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    157\u001b[0m chat_summary, deal_status, sentiment_result \u001b[38;5;241m=\u001b[39m analyze_sentiment_and_summary(chat_history)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Append data to Google Sheets including the generated summary\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m append_to_google_sheets(sheets_client, spreadsheet_id, [\n\u001b[0;32m    161\u001b[0m     buyer_name,\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(numbered_inputs),\n\u001b[0;32m    163\u001b[0m     summary[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary_text\u001b[39m\u001b[38;5;124m'\u001b[39m],  \u001b[38;5;66;03m# Enter the generated summary into the spreadsheet\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     sentiment_result,\n\u001b[0;32m    165\u001b[0m     deal_status\n\u001b[0;32m    166\u001b[0m ])\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChat session finalized and logged in Google Sheets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 108\u001b[0m, in \u001b[0;36mappend_to_google_sheets\u001b[1;34m(client, spreadsheet_id, row)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend_to_google_sheets\u001b[39m(client, spreadsheet_id, row):\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Appends a row to the specified Google Sheets spreadsheet.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mopen_by_key(spreadsheet_id)\u001b[38;5;241m.\u001b[39msheet1\n\u001b[0;32m    109\u001b[0m     sheet\u001b[38;5;241m.\u001b[39mappend_row(row)\n",
      "File \u001b[1;32mr:\\New folder\\anaconda.com\\Lib\\site-packages\\gspread\\client.py:158\u001b[0m, in \u001b[0;36mClient.open_by_key\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m APIError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m HTTPStatus\u001b[38;5;241m.\u001b[39mNOT_FOUND:\n\u001b[1;32m--> 158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SpreadsheetNotFound(ex\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m HTTPStatus\u001b[38;5;241m.\u001b[39mFORBIDDEN:\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mSpreadsheetNotFound\u001b[0m: <Response [404]>"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "from transformers import pipeline\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# Function to record audio\n",
    "def record_audio_chunk(chunk_duration=6, file_name=\"buyer_audio.wav\"):\n",
    "    \"\"\"Records a chunk of audio for the specified duration.\"\"\"\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    rate = 44100\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk)\n",
    "\n",
    "    print(\"Listening for the buyer's input...\")\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(rate / chunk * chunk_duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(file_name, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "    return file_name\n",
    "\n",
    "# Function to transcribe audio to text\n",
    "def transcribe_audio(file_name=\"buyer_audio.wav\"):\n",
    "    \"\"\"Transcribes audio to text using Google Speech Recognition.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(file_name) as source:\n",
    "        print(\"Processing audio transcription...\")\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            print(f\"Transcription: {text}\")\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"No clear speech detected in the last chunk.\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Error in request: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "# Function to format customer queries into a conversational structure\n",
    "def format_customer_inquiry(inquiry):\n",
    "    formatted_text = \"\"\"\n",
    "    Customer Inquiry Summary:\n",
    "    \"\"\"\n",
    "    for i, question in enumerate(inquiry, 1):\n",
    "        formatted_text += f\"{i}. Customer is asking about {question}.\\n\"\n",
    "    return formatted_text\n",
    "\n",
    "# Summarization and sentiment analysis pipeline\n",
    "def analyze_sentiment_and_summary(chat_history):\n",
    "    \"\"\"Analyzes the sentiment and summarizes the chat history in one sentence.\"\"\"\n",
    "    # Extract the last line from the chat history\n",
    "    last_line = chat_history.strip().split('\\n')[-1]\n",
    "\n",
    "    # Summarization pipeline (summarize the last line only)\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    summary = summarizer(last_line, max_length=20, min_length=5, do_sample=False)\n",
    "    summary_text = summary[0]['summary_text']\n",
    "    # Sentiment pipeline\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    sentiment_result = sentiment_pipeline(summary_text)[0]['label']\n",
    "\n",
    "    # Map sentiment labels to \"Positive\" or \"Negative\"\n",
    "    sentiment_result = \"Positive\" if sentiment_result == \"POSITIVE\" else \"Negative\"\n",
    "\n",
    "    # Additional checks for negative sentiment based on indecision or exploring alternatives\n",
    "    negative_cues = [\"check other options\", \"alternatives\", \"look at other deals\", \"explore other options\", \"not sure\", \"undecided\",\"check elsewhere\"]\n",
    "\n",
    "    if any(cue in chat_history.lower() for cue in negative_cues):\n",
    "        sentiment_result = \"Negative\"\n",
    "        \n",
    "    # Determine deal status based on sentiment\n",
    "    deal_status = \"closed\" if sentiment_result == \"Positive\" else \"not closed\"\n",
    "\n",
    "    return summary_text, deal_status, sentiment_result\n",
    "\n",
    "def initialize_google_sheets(credentials_path):\n",
    "    \"\"\"Initializes the Google Sheets integration.\"\"\"\n",
    "    scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(credentials_path, scope)\n",
    "    client = gspread.authorize(credentials)\n",
    "    return client\n",
    "\n",
    "def append_to_google_sheets(client, spreadsheet_id, row):\n",
    "    \"\"\"Appends a row to the specified Google Sheets spreadsheet.\"\"\"\n",
    "    sheet = client.open_by_key(spreadsheet_id).sheet1\n",
    "    sheet.append_row(row)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main workflow for continuous buyer interaction.\"\"\"\n",
    "    credentials_path = \"credentials1.json\"  # Path to your Google credentials file\n",
    "    spreadsheet_id = \"1Xv7HMn91ddcXhGXeLX-6jxYuVegfgnPIpFIPsZhcvPc\"  # Replace with your spreadsheet ID\n",
    "    sheets_client = initialize_google_sheets(credentials_path)\n",
    "\n",
    "    print(\"Starting continuous buyer interaction...\")\n",
    "\n",
    "    buyer_name = input(\"Please enter the buyer's name: \")\n",
    "    chat_history = \"\"\n",
    "    numbered_inputs = []\n",
    "    customer_inquiries = []\n",
    "\n",
    "    while True:\n",
    "        # Record and transcribe the buyer's audio input\n",
    "        audio_file = record_audio_chunk()\n",
    "        transcribed_text = transcribe_audio(audio_file)\n",
    "        if not transcribed_text:\n",
    "            print(\"Waiting for the next buyer input...\\n\")\n",
    "            time.sleep(4)  # Pause to wait for the buyer to speak\n",
    "            continue\n",
    "\n",
    "        numbered_inputs.append(f\"{len(numbered_inputs) + 1}. {transcribed_text}\")\n",
    "        customer_inquiries.append(transcribed_text)  # Add to the customer inquiries\n",
    "        chat_history += f\"{transcribed_text}\\n\"\n",
    "\n",
    "        print(f\"\\nBuyer Transcription: {transcribed_text}\")\n",
    "        print(\"Waiting for the next interaction...\\n\")\n",
    "\n",
    "        # Simulate a button to end chat\n",
    "        end_chat = input(\"Type 'end' to finalize the chat or press Enter to continue: \")\n",
    "        if end_chat.lower() == 'end':\n",
    "            break\n",
    "\n",
    "    # Format the input text based on dynamic customer queries\n",
    "    formatted_text = format_customer_inquiry(customer_inquiries)\n",
    "\n",
    "    # Summarize the customer inquiry\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    summary = summarizer(formatted_text, max_length=200, min_length=50, do_sample=False)\n",
    "\n",
    "    # Print the generated summary\n",
    "    print(\"Generated Summary:\")\n",
    "    print(summary[0]['summary_text'])\n",
    "\n",
    "    # Finalize summary, sentiment, and deal status\n",
    "    chat_summary, deal_status, sentiment_result = analyze_sentiment_and_summary(chat_history)\n",
    "\n",
    "    # Append data to Google Sheets including the generated summary\n",
    "    append_to_google_sheets(sheets_client, spreadsheet_id, [\n",
    "        buyer_name,\n",
    "        '\\n'.join(numbered_inputs),\n",
    "        summary[0]['summary_text'],  # Enter the generated summary into the spreadsheet\n",
    "        sentiment_result,\n",
    "        deal_status\n",
    "    ])\n",
    "\n",
    "    print(\"Chat session finalized and logged in Google Sheets.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
